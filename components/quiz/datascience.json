{
  "categories": [
    {
      "name": "Data Science",
      "questions": [
        {
          "id": 1,
          "question": "What is data science?",
          "options": [
            "A field focused on hardware manufacturing",
            "A discipline that uses scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data",
            "A type of data compression technique",
            "A specialized area of network administration"
          ],
          "answer": "A discipline that uses scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data",
          "difficulty": "Easy",
          "explanation": "Data science combines statistics, computer science, and domain knowledge to analyze and interpret complex data."
        },
        {
          "id": 2,
          "question": "Which of the following programming languages is most commonly used in data science?",
          "options": [
            "R and Python",
            "C++ and Assembly",
            "HTML and CSS",
            "PHP and Perl"
          ],
          "answer": "R and Python",
          "difficulty": "Easy",
          "explanation": "R and Python are the most popular languages due to their rich ecosystems of libraries and frameworks for data analysis and machine learning."
        },
        {
          "id": 3,
          "question": "What is a Jupyter Notebook?",
          "options": [
            "A special type of computer hardware",
            "A web-based interactive environment for creating and sharing documents with code, visualizations, and narrative text",
            "A version control system",
            "A data encryption tool"
          ],
          "answer": "A web-based interactive environment for creating and sharing documents with code, visualizations, and narrative text",
          "difficulty": "Easy",
          "explanation": "Jupyter Notebooks allow data scientists to write and execute code, visualize results, and document their process in one place."
        },
        {
          "id": 4,
          "question": "What is the CRISP-DM methodology?",
          "options": [
            "A machine learning algorithm",
            "A framework for data mining projects, including phases such as business understanding, data preparation, modeling, evaluation, and deployment",
            "A tool for database indexing",
            "A deep learning architecture"
          ],
          "answer": "A framework for data mining projects, including phases such as business understanding, data preparation, modeling, evaluation, and deployment",
          "difficulty": "Medium",
          "explanation": "CRISP-DM (Cross-Industry Standard Process for Data Mining) provides a structured approach to data science projects."
        },
        {
          "id": 5,
          "question": "What is exploratory data analysis (EDA)?",
          "options": [
            "A way to directly deploy machine learning models",
            "A process of analyzing data sets to summarize their main characteristics using visual methods",
            "A technique for hardware optimization",
            "A process of encrypting data before storage"
          ],
          "answer": "A process of analyzing data sets to summarize their main characteristics using visual methods",
          "difficulty": "Easy",
          "explanation": "EDA helps data scientists understand patterns, spot anomalies, and check assumptions using statistical summaries and visualizations."
        },
        {
          "id": 6,
          "question": "Which library is commonly used in Python for data manipulation and analysis?",
          "options": ["Pandas", "Requests", "Django", "Flask"],
          "answer": "Pandas",
          "difficulty": "Easy",
          "explanation": "Pandas provides data structures like DataFrames and operations for manipulating numerical tables and time series."
        },
        {
          "id": 7,
          "question": "What is a DataFrame?",
          "options": [
            "A data visualization technique",
            "A 2D labeled data structure, similar to a table, commonly used in pandas",
            "A programming language",
            "A neural network architecture"
          ],
          "answer": "A 2D labeled data structure, similar to a table, commonly used in pandas",
          "difficulty": "Easy",
          "explanation": "DataFrames are key pandas objects that store data in rows and columns, making manipulation and analysis more intuitive."
        },
        {
          "id": 8,
          "question": "What is feature engineering?",
          "options": [
            "The process of training neural networks",
            "The selection, creation, or transformation of variables (features) to improve model performance",
            "A method of hardware optimization",
            "A process for writing technical documentation"
          ],
          "answer": "The selection, creation, or transformation of variables (features) to improve model performance",
          "difficulty": "Medium",
          "explanation": "Feature engineering improves the predictive power of models by crafting meaningful input variables."
        },
        {
          "id": 9,
          "question": "Which of the following is an example of supervised learning?",
          "options": [
            "Clustering customer data without labels",
            "Predicting house prices based on historical, labeled data",
            "Reducing dimensionality of a dataset",
            "Discovering patterns in unlabeled text documents"
          ],
          "answer": "Predicting house prices based on historical, labeled data",
          "difficulty": "Easy",
          "explanation": "Supervised learning uses labeled examples to train models to predict outcomes for new unseen data."
        },
        {
          "id": 10,
          "question": "What is the difference between classification and regression?",
          "options": [
            "Classification predicts continuous values, regression predicts categorical classes",
            "They are the same task",
            "Classification predicts categorical classes, regression predicts continuous values",
            "Regression is only used for images"
          ],
          "answer": "Classification predicts categorical classes, regression predicts continuous values",
          "difficulty": "Easy",
          "explanation": "Classification problems predict discrete categories, while regression problems predict numeric continuous values."
        },
        {
          "id": 11,
          "question": "What is cross-validation?",
          "options": [
            "A technique to reduce overfitting by splitting data into multiple train/test subsets",
            "A way to visualize data",
            "A data cleaning method",
            "A database indexing strategy"
          ],
          "answer": "A technique to reduce overfitting by splitting data into multiple train/test subsets",
          "difficulty": "Medium",
          "explanation": "Cross-validation helps get a better estimate of a model’s performance by training and testing it on multiple data splits."
        },
        {
          "id": 12,
          "question": "What is a confusion matrix?",
          "options": [
            "A matrix used to optimize regression models",
            "A table showing the counts of actual vs. predicted classes in classification tasks",
            "A matrix for data encryption",
            "A dimensionality reduction technique"
          ],
          "answer": "A table showing the counts of actual vs. predicted classes in classification tasks",
          "difficulty": "Easy",
          "explanation": "A confusion matrix helps visualize the performance of a classification model by showing true positives, false positives, etc."
        },
        {
          "id": 13,
          "question": "What is precision in classification metrics?",
          "options": [
            "The ratio of true positives to all predicted positives",
            "The ratio of true positives to all actual positives",
            "The ratio of correctly predicted instances over total instances",
            "A measure of how well the model explains variance"
          ],
          "answer": "The ratio of true positives to all predicted positives",
          "difficulty": "Medium",
          "explanation": "Precision focuses on the quality of positive predictions—how many of the predicted positives are actually correct."
        },
        {
          "id": 14,
          "question": "What is recall?",
          "options": [
            "The ratio of true positives to all predicted positives",
            "The ratio of true positives to all actual positives",
            "The difference between predicted and actual values",
            "A method of data cleaning"
          ],
          "answer": "The ratio of true positives to all actual positives",
          "difficulty": "Medium",
          "explanation": "Recall (also known as sensitivity) measures how many of the actual positives the model correctly identified."
        },
        {
          "id": 15,
          "question": "What is the F1-score?",
          "options": [
            "A performance metric that is the harmonic mean of precision and recall",
            "A type of neural network layer",
            "A method for visualizing data distributions",
            "A technique for dimensionality reduction"
          ],
          "answer": "A performance metric that is the harmonic mean of precision and recall",
          "difficulty": "Medium",
          "explanation": "The F1-score balances precision and recall, making it a useful single measure for classification performance."
        },
        {
          "id": 16,
          "question": "What is overfitting?",
          "options": [
            "When a model performs poorly on both training and test data",
            "When a model fits training data too closely and fails to generalize to new data",
            "When a model ignores the training data",
            "When a model only handles linear relationships"
          ],
          "answer": "When a model fits training data too closely and fails to generalize to new data",
          "difficulty": "Easy",
          "explanation": "Overfitting occurs when a model memorizes training data details and noise, hurting its performance on unseen data."
        },
        {
          "id": 17,
          "question": "What technique can help prevent overfitting?",
          "options": [
            "Using the entire dataset for training only",
            "Adding more features",
            "Regularization methods like L2 or dropout",
            "Reducing the training data size"
          ],
          "answer": "Regularization methods like L2 or dropout",
          "difficulty": "Medium",
          "explanation": "Regularization introduces penalties or constraints that discourage overly complex models, improving generalization."
        },
        {
          "id": 18,
          "question": "What is regularization?",
          "options": [
            "A method to speed up computation",
            "A way to reduce model complexity and prevent overfitting",
            "A data visualization technique",
            "A database normalization method"
          ],
          "answer": "A way to reduce model complexity and prevent overfitting",
          "difficulty": "Medium",
          "explanation": "Regularization techniques (like L1, L2) add constraints to model parameters, leading to simpler, more generalizable models."
        },
        {
          "id": 19,
          "question": "What is a decision tree?",
          "options": [
            "A linear model",
            "A tree-structured model that splits data based on feature values",
            "A neural network architecture",
            "A database indexing method"
          ],
          "answer": "A tree-structured model that splits data based on feature values",
          "difficulty": "Easy",
          "explanation": "Decision trees recursively split the dataset into branches based on features, leading to a prediction at the leaves."
        },
        {
          "id": 20,
          "question": "What is ensemble learning?",
          "options": [
            "Using a single model for predictions",
            "Combining multiple models to improve performance",
            "A method for data normalization",
            "A hardware acceleration technique"
          ],
          "answer": "Combining multiple models to improve performance",
          "difficulty": "Medium",
          "explanation": "Ensemble methods like Random Forests or Gradient Boosting aggregate predictions from multiple models to reduce errors."
        },
        {
          "id": 21,
          "question": "What is Random Forest?",
          "options": [
            "A single decision tree",
            "An ensemble of decision trees that vote on predictions",
            "A clustering algorithm",
            "A linear regression model"
          ],
          "answer": "An ensemble of decision trees that vote on predictions",
          "difficulty": "Easy",
          "explanation": "Random Forest constructs multiple decision trees from random subsets of data and features, improving robustness."
        },
        {
          "id": 22,
          "question": "What is gradient boosting?",
          "options": [
            "An unsupervised method for outlier detection",
            "An ensemble technique that builds new models to correct the errors of previous models",
            "A dimensionality reduction technique",
            "A method of tuning hyperparameters"
          ],
          "answer": "An ensemble technique that builds new models to correct the errors of previous models",
          "difficulty": "Medium",
          "explanation": "Gradient boosting sequentially adds weak learners, each one trying to fix errors from the preceding ensemble."
        },
        {
          "id": 23,
          "question": "What is unsupervised learning?",
          "options": [
            "Learning from labeled data",
            "Learning from unlabeled data to find patterns or groupings",
            "A technique for hyperparameter tuning",
            "A method for image classification"
          ],
          "answer": "Learning from unlabeled data to find patterns or groupings",
          "difficulty": "Easy",
          "explanation": "Unsupervised learning algorithms, like clustering, find structure in data without predefined labels."
        },
        {
          "id": 24,
          "question": "What is k-means clustering?",
          "options": [
            "A supervised learning method",
            "An algorithm that partitions data into k clusters based on similarity",
            "A reinforcement learning algorithm",
            "A regression method"
          ],
          "answer": "An algorithm that partitions data into k clusters based on similarity",
          "difficulty": "Easy",
          "explanation": "K-means tries to group data points into k clusters, minimizing variance within each cluster."
        },
        {
          "id": 25,
          "question": "What is dimensionality reduction?",
          "options": [
            "A method to increase the number of features",
            "A technique to reduce the number of variables while retaining important information",
            "A form of regularization",
            "A method for hyperparameter tuning"
          ],
          "answer": "A technique to reduce the number of variables while retaining important information",
          "difficulty": "Medium",
          "explanation": "Dimensionality reduction simplifies data, often improving model performance and interpretability."
        },
        {
          "id": 26,
          "question": "What is Principal Component Analysis (PCA)?",
          "options": [
            "A supervised learning algorithm",
            "An unsupervised technique for dimensionality reduction that identifies principal components of variance",
            "A clustering algorithm",
            "A cryptographic algorithm"
          ],
          "answer": "An unsupervised technique for dimensionality reduction that identifies principal components of variance",
          "difficulty": "Medium",
          "explanation": "PCA transforms data into a set of orthogonal components capturing the most variance, reducing dimensionality."
        },
        {
          "id": 27,
          "question": "What is a neural network?",
          "options": [
            "A linear model for regression",
            "A model inspired by the human brain structure, consisting of interconnected nodes (neurons)",
            "A rule-based system",
            "A simple data cleaning method"
          ],
          "answer": "A model inspired by the human brain structure, consisting of interconnected nodes (neurons)",
          "difficulty": "Easy",
          "explanation": "Neural networks learn to extract features and patterns by adjusting weights between interconnected units."
        },
        {
          "id": 28,
          "question": "What is deep learning?",
          "options": [
            "A shallow decision tree model",
            "A subset of machine learning using multi-layer neural networks to learn representations from large amounts of data",
            "A method of data normalization",
            "A technique for database indexing"
          ],
          "answer": "A subset of machine learning using multi-layer neural networks to learn representations from large amounts of data",
          "difficulty": "Easy",
          "explanation": "Deep learning uses neural networks with many layers to automatically learn complex features from raw data."
        },
        {
          "id": 29,
          "question": "What is overfitting in deep learning?",
          "options": [
            "A situation where the model under-performs on both training and test data",
            "When the model learns the training data patterns too well, including noise, leading to poor test performance",
            "A method of regularization",
            "An initial preprocessing step"
          ],
          "answer": "When the model learns the training data patterns too well, including noise, leading to poor test performance",
          "difficulty": "Medium",
          "explanation": "Deep models with many parameters can easily overfit, memorizing training data without learning general patterns."
        },
        {
          "id": 30,
          "question": "What is batch normalization?",
          "options": [
            "A method of normalizing the entire dataset at once",
            "A technique to normalize inputs of each layer to speed up training and improve stability",
            "A regularization method that removes layers",
            "A method for data augmentation"
          ],
          "answer": "A technique to normalize inputs of each layer to speed up training and improve stability",
          "difficulty": "Hard",
          "explanation": "Batch normalization reduces internal covariate shift, stabilizing learning and often improving performance in neural networks."
        },
        {
          "id": 31,
          "question": "What is hyperparameter tuning?",
          "options": [
            "Adjusting parameters learned during training",
            "Optimizing user-defined parameters (like learning rate, number of layers) that are not directly learned from data",
            "A step in data cleaning",
            "A method for merging datasets"
          ],
          "answer": "Optimizing user-defined parameters (like learning rate, number of layers) that are not directly learned from data",
          "difficulty": "Medium",
          "explanation": "Hyperparameters control the model training process and must be chosen carefully to improve model performance."
        },
        {
          "id": 32,
          "question": "What is a learning rate in machine learning?",
          "options": [
            "A metric for model accuracy",
            "A hyperparameter that controls the step size at each iteration of optimization",
            "A data normalization factor",
            "A type of activation function"
          ],
          "answer": "A hyperparameter that controls the step size at each iteration of optimization",
          "difficulty": "Easy",
          "explanation": "The learning rate determines how quickly or slowly a model updates its parameters during training."
        },
        {
          "id": 33,
          "question": "What is stochastic gradient descent (SGD)?",
          "options": [
            "A method of dimensionality reduction",
            "A variant of gradient descent that updates parameters using a single or small batch of training examples",
            "A data storage format",
            "A clustering algorithm"
          ],
          "answer": "A variant of gradient descent that updates parameters using a single or small batch of training examples",
          "difficulty": "Medium",
          "explanation": "SGD often speeds up training and helps models escape local minima compared to batch gradient descent."
        },
        {
          "id": 34,
          "question": "What is a loss function?",
          "options": [
            "A tool for data visualization",
            "A function that measures how far the model’s predictions are from the actual values",
            "A method of data cleaning",
            "A step in model deployment"
          ],
          "answer": "A function that measures how far the model’s predictions are from the actual values",
          "difficulty": "Easy",
          "explanation": "The loss function quantifies the model’s errors, guiding the learning process to reduce these errors."
        },
        {
          "id": 35,
          "question": "What is L1 regularization (Lasso)?",
          "options": [
            "A technique to increase model complexity",
            "A penalty on the absolute values of parameters, encouraging sparsity",
            "A type of activation function in neural networks",
            "A measure of model accuracy"
          ],
          "answer": "A penalty on the absolute values of parameters, encouraging sparsity",
          "difficulty": "Medium",
          "explanation": "L1 regularization tends to produce models with fewer active features by driving some weights to zero."
        },
        {
          "id": 36,
          "question": "What is L2 regularization (Ridge)?",
          "options": [
            "A penalty on the squared values of parameters, discouraging large weights",
            "A method of data normalization",
            "A hyperparameter tuning technique",
            "A clustering method"
          ],
          "answer": "A penalty on the squared values of parameters, discouraging large weights",
          "difficulty": "Medium",
          "explanation": "L2 regularization reduces complexity by penalizing large weights, leading to more evenly distributed parameter values."
        },
        {
          "id": 37,
          "question": "What is a time series in data analysis?",
          "options": [
            "A collection of random data points",
            "Data points indexed in time order, often used for forecasting",
            "A type of unsupervised learning task",
            "A method of feature engineering"
          ],
          "answer": "Data points indexed in time order, often used for forecasting",
          "difficulty": "Easy",
          "explanation": "Time series data, like stock prices or weather data, are analyzed for trends, seasonality, and forecasting."
        },
        {
          "id": 38,
          "question": "What is ARIMA in time series analysis?",
          "options": [
            "A clustering algorithm",
            "A model for time series forecasting combining Autoregressive, Integrated, and Moving Average components",
            "A deep learning framework",
            "A dimensionality reduction technique"
          ],
          "answer": "A model for time series forecasting combining Autoregressive, Integrated, and Moving Average components",
          "difficulty": "Hard",
          "explanation": "ARIMA models are widely used to understand and predict future points in time series data."
        },
        {
          "id": 39,
          "question": "What is data cleaning?",
          "options": [
            "Removing all data",
            "The process of fixing or removing incorrect, corrupted, or irrelevant data",
            "A method of deploying models",
            "A feature of Jupyter Notebook"
          ],
          "answer": "The process of fixing or removing incorrect, corrupted, or irrelevant data",
          "difficulty": "Easy",
          "explanation": "Data cleaning ensures that the dataset used for analysis or modeling is accurate and reliable."
        },
        {
          "id": 40,
          "question": "What is data normalization?",
          "options": [
            "A technique to scale numerical features so they have similar ranges",
            "A method of increasing dataset size",
            "A clustering algorithm",
            "A process for building neural networks"
          ],
          "answer": "A technique to scale numerical features so they have similar ranges",
          "difficulty": "Medium",
          "explanation": "Normalization or standardization helps many algorithms converge faster and avoid bias due to differently scaled features."
        },
        {
          "id": 41,
          "question": "What is a histogram?",
          "options": [
            "A type of line plot",
            "A graphical representation of the distribution of numerical data using bars",
            "A clustering technique",
            "A dimensionality reduction method"
          ],
          "answer": "A graphical representation of the distribution of numerical data using bars",
          "difficulty": "Easy",
          "explanation": "Histograms show how frequently data points fall into specified value ranges (bins)."
        },
        {
          "id": 42,
          "question": "What is a box plot?",
          "options": [
            "A regression method",
            "A visualization that shows the distribution of data based on quartiles, highlighting median and outliers",
            "A security technique",
            "A deep learning model"
          ],
          "answer": "A visualization that shows the distribution of data based on quartiles, highlighting median and outliers",
          "difficulty": "Easy",
          "explanation": "Box plots summarize data distribution, central value, and variability, as well as detecting outliers."
        },
        {
          "id": 43,
          "question": "What is correlation?",
          "options": [
            "A causal relationship between two variables",
            "A measure of the linear relationship between two variables",
            "A supervised learning metric",
            "A method for encoding categorical data"
          ],
          "answer": "A measure of the linear relationship between two variables",
          "difficulty": "Easy",
          "explanation": "Correlation measures the strength and direction of a linear relationship between two variables."
        },
        {
          "id": 44,
          "question": "What is data wrangling?",
          "options": [
            "A technique for deploying models",
            "The process of cleaning, reshaping, and transforming raw data into a more usable form",
            "A hyperparameter tuning method",
            "A hardware optimization technique"
          ],
          "answer": "The process of cleaning, reshaping, and transforming raw data into a more usable form",
          "difficulty": "Medium",
          "explanation": "Data wrangling prepares data for analysis, often a large part of a data scientist’s workload."
        },
        {
          "id": 45,
          "question": "What is a recommender system?",
          "options": [
            "A system that classifies images",
            "A tool that recommends which programming language to use",
            "A system that suggests items to users based on their preferences or behavior",
            "A way to partition data into clusters"
          ],
          "answer": "A system that suggests items to users based on their preferences or behavior",
          "difficulty": "Medium",
          "explanation": "Recommender systems use algorithms and user data to present personalized product or content suggestions."
        },
        {
          "id": 46,
          "question": "What is data augmentation?",
          "options": [
            "A method to reduce data size",
            "The process of increasing training data by generating new examples from existing data, often used in image and text tasks",
            "A dimensionality reduction technique",
            "A network architecture in deep learning"
          ],
          "answer": "The process of increasing training data by generating new examples from existing data, often used in image and text tasks",
          "difficulty": "Medium",
          "explanation": "Data augmentation improves model robustness by synthesizing new examples through transformations like rotations or crops."
        },
        {
          "id": 47,
          "question": "What is a KPI (Key Performance Indicator) in data science?",
          "options": [
            "A data cleaning tool",
            "A quantitative measure used to evaluate the success of an organization or model",
            "A type of regression metric",
            "A clustering algorithm"
          ],
          "answer": "A quantitative measure used to evaluate the success of an organization or model",
          "difficulty": "Easy",
          "explanation": "KPIs are used to track performance against goals, such as accuracy, profit, or user engagement."
        },
        {
          "id": 48,
          "question": "What is A/B testing?",
          "options": [
            "A method of model regularization",
            "A controlled experiment comparing two variants (A and B) to determine which performs better",
            "A technique to normalize data",
            "A method for hyperparameter optimization"
          ],
          "answer": "A controlled experiment comparing two variants (A and B) to determine which performs better",
          "difficulty": "Medium",
          "explanation": "A/B testing is often used in product optimization, marketing campaigns, or UI changes to see what leads to better results."
        },
        {
          "id": 49,
          "question": "What is a data pipeline?",
          "options": [
            "A method to secure data",
            "A series of data processing steps from raw input to final output, often involving extraction, transformation, and loading (ETL)",
            "A regression model",
            "A type of decision tree"
          ],
          "answer": "A series of data processing steps from raw input to final output, often involving extraction, transformation, and loading (ETL)",
          "difficulty": "Medium",
          "explanation": "Data pipelines automate the flow of data from source systems to analysis or storage, ensuring consistent and repeatable processes."
        },
        {
          "id": 50,
          "question": "What is model deployment?",
          "options": [
            "The process of just training the model",
            "Integrating a trained model into a production environment to make predictions on real-world data",
            "A step in data cleaning",
            "A visualization technique"
          ],
          "answer": "Integrating a trained model into a production environment to make predictions on real-world data",
          "difficulty": "Easy",
          "explanation": "Deployment makes the model available for use in real applications, turning insights into actionable results."
        }
      ]
    }
  ]
}
